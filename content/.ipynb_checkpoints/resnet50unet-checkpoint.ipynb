{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: First Post\n",
    "Slug: first-post\n",
    "Date: 2018-10-22\n",
    "Category: posts\n",
    "Tags: python firsts\n",
    "author: Chris Dinant\n",
    "Summary: My first post, read it to find out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Category": "posts",
    "Date": "2018-10-22",
    "Slug": "first-post",
    "Summary": "My first post, read it to find out.",
    "Tags": "python firsts",
    "Title": "First Post",
    "author": "Chris Dinant"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.utils import *\n",
    "import scripts.loss_functions as ls\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "import numpy as np\n",
    "from skimage.transform import rescale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train/'\n",
    "test_path = '../data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from scripts.utils import i_m_generator, train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(train_path+'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, val = train_val_split(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = i_m_generator(train_path+'images/', tr, train_path+'masks/', train = True,\n",
    "                   crop = False, width_shift = False, horizontal_flip = True, batch_size = batch_size, dim = 224, ch = 3)\n",
    "val_gen = i_m_generator(train_path+'images/', val, train_path+'masks/', train = True,\n",
    "                   crop = False, width_shift = False, horizontal_flip = True, batch_size = batch_size, dim = 224, ch = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_first_3_blocks = Model(base_model.input, outputs=base_model.get_layer('conv2_block3_concat').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 159,808\n",
      "Trainable params: 158,336\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_first_3_blocks.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MaxPooling2D()(dense_first_3_blocks.output)\n",
    "x = Conv2D(256, 3, padding = 'same', activation = 'relu')(x)\n",
    "x = Conv2DTranspose(128, (2,2), strides = (2,2), padding = 'same', activation = 'relu')(x)\n",
    "x = Add()([block(128, x),x])\n",
    "x = Add()([block(128, x),x])\n",
    "x = Add()([block(128, x),x])\n",
    "x = concatenate([dense_first_3_blocks.get_layer(\"conv2_block3_0_bn\").output,x])\n",
    "x = Conv2DTranspose(64, (2,2), strides = (2,2), padding = 'same', activation = 'relu')(x)\n",
    "x = Add()([block(64, x),x])\n",
    "x = Add()([block(64, x),x])\n",
    "x = Add()([block(64, x),x])\n",
    "x = concatenate([dense_first_3_blocks.get_layer(\"conv1/relu\").output,x])\n",
    "x = Conv2D(64, 3, padding = 'same', activation = 'relu')(x)\n",
    "out = Conv2DTranspose(1, (2,2), strides = (2,2), padding = 'same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(dense_first_3_blocks.input, out)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:26]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adadelta', loss=ls.bce_dice_loss, metrics = [competitionMetric2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint('../models/model-tgs-salt-25_dense.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6969 - competitionMetric2: 0.4141\n",
      "Epoch 00001: val_loss improved from inf to 2.25036, saving model to ../models/model-tgs-salt-25_dense.h5\n",
      "112/112 [==============================] - 52s 464ms/step - loss: 0.6953 - competitionMetric2: 0.4132 - val_loss: 2.2504 - val_competitionMetric2: 0.1823\n",
      "Epoch 2/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5199 - competitionMetric2: 0.5395\n",
      "Epoch 00002: val_loss improved from 2.25036 to 1.00120, saving model to ../models/model-tgs-salt-25_dense.h5\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.5211 - competitionMetric2: 0.5398 - val_loss: 1.0012 - val_competitionMetric2: 0.3198\n",
      "Epoch 3/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4745 - competitionMetric2: 0.5716\n",
      "Epoch 00003: val_loss improved from 1.00120 to 0.81129, saving model to ../models/model-tgs-salt-25_dense.h5\n",
      "112/112 [==============================] - 41s 363ms/step - loss: 0.4738 - competitionMetric2: 0.5720 - val_loss: 0.8113 - val_competitionMetric2: 0.3701\n",
      "Epoch 4/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4521 - competitionMetric2: 0.5835\n",
      "Epoch 00004: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 361ms/step - loss: 0.4515 - competitionMetric2: 0.5830 - val_loss: 1.0520 - val_competitionMetric2: 0.3714\n",
      "Epoch 5/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4295 - competitionMetric2: 0.6014\n",
      "Epoch 00005: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.4298 - competitionMetric2: 0.6004 - val_loss: 1.0229 - val_competitionMetric2: 0.3289\n",
      "Epoch 6/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4142 - competitionMetric2: 0.6097\n",
      "Epoch 00006: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 365ms/step - loss: 0.4137 - competitionMetric2: 0.6101 - val_loss: 1.2785 - val_competitionMetric2: 0.3492\n",
      "Epoch 7/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4152 - competitionMetric2: 0.6195\n",
      "Epoch 00007: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 42s 373ms/step - loss: 0.4150 - competitionMetric2: 0.6201 - val_loss: 1.0334 - val_competitionMetric2: 0.3542\n",
      "Epoch 8/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3934 - competitionMetric2: 0.6172\n",
      "Epoch 00008: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 367ms/step - loss: 0.3932 - competitionMetric2: 0.6169 - val_loss: 1.0556 - val_competitionMetric2: 0.3724\n",
      "Epoch 9/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3896 - competitionMetric2: 0.6293\n",
      "Epoch 00009: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 370ms/step - loss: 0.3903 - competitionMetric2: 0.6296 - val_loss: 0.9792 - val_competitionMetric2: 0.3729\n",
      "Epoch 10/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3807 - competitionMetric2: 0.6266\n",
      "Epoch 00010: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 39s 349ms/step - loss: 0.3839 - competitionMetric2: 0.6243 - val_loss: 0.9889 - val_competitionMetric2: 0.3544\n",
      "Epoch 11/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3724 - competitionMetric2: 0.6499\n",
      "Epoch 00011: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 354ms/step - loss: 0.3729 - competitionMetric2: 0.6500 - val_loss: 1.4452 - val_competitionMetric2: 0.3083\n",
      "Epoch 12/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4010 - competitionMetric2: 0.6269\n",
      "Epoch 00012: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 360ms/step - loss: 0.4002 - competitionMetric2: 0.6271 - val_loss: 1.0143 - val_competitionMetric2: 0.3831\n",
      "Epoch 13/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3446 - competitionMetric2: 0.6544\n",
      "Epoch 00013: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.3442 - competitionMetric2: 0.6538 - val_loss: 1.2940 - val_competitionMetric2: 0.3234\n",
      "Epoch 14/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3791 - competitionMetric2: 0.6380\n",
      "Epoch 00014: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 363ms/step - loss: 0.3788 - competitionMetric2: 0.6389 - val_loss: 0.9805 - val_competitionMetric2: 0.4563\n",
      "Epoch 15/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3564 - competitionMetric2: 0.6595\n",
      "Epoch 00015: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.3568 - competitionMetric2: 0.6597 - val_loss: 1.0468 - val_competitionMetric2: 0.3872\n",
      "Epoch 16/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3307 - competitionMetric2: 0.6616\n",
      "Epoch 00016: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 360ms/step - loss: 0.3295 - competitionMetric2: 0.6616 - val_loss: 1.3382 - val_competitionMetric2: 0.3711\n",
      "Epoch 17/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3460 - competitionMetric2: 0.6517\n",
      "Epoch 00017: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 367ms/step - loss: 0.3452 - competitionMetric2: 0.6524 - val_loss: 1.8156 - val_competitionMetric2: 0.4266\n",
      "Epoch 18/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3491 - competitionMetric2: 0.6539\n",
      "Epoch 00018: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.3478 - competitionMetric2: 0.6547 - val_loss: 1.1965 - val_competitionMetric2: 0.4156\n",
      "Epoch 19/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3344 - competitionMetric2: 0.6628\n",
      "Epoch 00019: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 358ms/step - loss: 0.3362 - competitionMetric2: 0.6622 - val_loss: 0.8530 - val_competitionMetric2: 0.4112\n",
      "Epoch 20/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3306 - competitionMetric2: 0.6669\n",
      "Epoch 00020: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 43s 381ms/step - loss: 0.3297 - competitionMetric2: 0.6686 - val_loss: 0.9475 - val_competitionMetric2: 0.3982\n",
      "Epoch 21/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3310 - competitionMetric2: 0.6600\n",
      "Epoch 00021: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.3303 - competitionMetric2: 0.6604 - val_loss: 0.9340 - val_competitionMetric2: 0.3456\n",
      "Epoch 22/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3218 - competitionMetric2: 0.6587\n",
      "Epoch 00022: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.3218 - competitionMetric2: 0.6587 - val_loss: 0.9032 - val_competitionMetric2: 0.4359\n",
      "Epoch 23/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3094 - competitionMetric2: 0.6700\n",
      "Epoch 00023: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.3099 - competitionMetric2: 0.6696 - val_loss: 1.1330 - val_competitionMetric2: 0.4302\n",
      "Epoch 24/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3184 - competitionMetric2: 0.6702\n",
      "Epoch 00024: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 40s 361ms/step - loss: 0.3190 - competitionMetric2: 0.6699 - val_loss: 0.9804 - val_competitionMetric2: 0.4474\n",
      "Epoch 25/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3030 - competitionMetric2: 0.6821\n",
      "Epoch 00025: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.3030 - competitionMetric2: 0.6818 - val_loss: 0.8911 - val_competitionMetric2: 0.4622\n",
      "Epoch 26/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3052 - competitionMetric2: 0.6787\n",
      "Epoch 00026: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 364ms/step - loss: 0.3046 - competitionMetric2: 0.6785 - val_loss: 1.3013 - val_competitionMetric2: 0.4995\n",
      "Epoch 27/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3131 - competitionMetric2: 0.6781\n",
      "Epoch 00027: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 370ms/step - loss: 0.3157 - competitionMetric2: 0.6757 - val_loss: 1.1284 - val_competitionMetric2: 0.4310\n",
      "Epoch 28/60\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2924 - competitionMetric2: 0.6805\n",
      "Epoch 00028: val_loss did not improve from 0.81129\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.2922 - competitionMetric2: 0.6797 - val_loss: 1.1141 - val_competitionMetric2: 0.4594\n",
      "Epoch 29/60\n",
      " 93/112 [=======================>......] - ETA: 6s - loss: 0.2834 - competitionMetric2: 0.6835"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-47e9f74c91d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                              \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                              shuffle = True)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 204\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                             steps_per_epoch = len(tr)//batch_size,\n",
    "                             epochs = 60,\n",
    "                             callbacks = [checkpointer],\n",
    "                             validation_data = val_gen,\n",
    "                             validation_steps = len(val)//batch_size,\n",
    "                             shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/model-tgs-salt-25_dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['competitionMetric2'])\n",
    "plt.plot(history.history['val_competitionMetric2'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('mean_iou')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.savefig('graphs/ctc_{}_acc.png'.format(date),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('graphs/ctc_{}_loss.png'.format(date), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_genn = i_m_generator(train_path+'images/', val, train_path+'masks/', train = True, shuffle = False,\n",
    "                   crop = False, width_shift = False, horizontal_flip = True, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.conda/envs/tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/chris/.conda/envs/tensorflow/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "X_val_pred = model.predict_generator(val_genn, steps = len(val)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc591129f28>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADwtJREFUeJzt3X+s3XV9x/HnawgloAaqQEipo5BqhstWsUESJnFjKpDFwhJdyaKdI6smkGjikhVNNrK/nBNNzDZMCcSyMH5MRPoHbtaGSEwGUrAWsAIFq1zatIoGyDBIy3t/nO+d53N7r73cc84955rnI7k53+/nfL7nvE++5cX3+z0n33eqCkma9jvjLkDSZDEUJDUMBUkNQ0FSw1CQ1DAUJDVGFgpJLk7yeJI9STaN6n0kDVdG8TuFJMcATwDvBaaAB4ErquoHQ38zSUM1qiOF84A9VfV0Vf0KuA1YN6L3kjRErxvR664AnulbnwLeNdfk47KsjufEEZUiCeBFfvGzqjrlaPNGFQqZZaw5T0myEdgIcDwn8K5cNKJSJAF8q7764/nMG9XpwxSwsm/9DGBf/4Sq2lxVa6tq7bEsG1EZkl6rUYXCg8DqJKuSHAesB7aO6L0kDdFITh+q6lCSq4H/Bo4Bbqqqx0bxXpKGa1TXFKiqe4B7RvX6kkbDXzRKahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqTGgkMhycok9ybZneSxJJ/oxq9N8mySnd3fpcMrV9KoDXKTlUPAp6rq4SRvAB5Ksq177otV9fnBy5O02BYcClW1H9jfLb+YZDe9W7tLWsKGck0hyZnAO4AHuqGrk+xKclOSk4fxHpIWx8ChkOT1wJ3AJ6vqBeB64GxgDb0jievm2G5jkh1JdrzCy4OWIWlIBgqFJMfSC4RbquprAFV1oKoOV9WrwA30Wsgdwb4P0mQa5NuHADcCu6vqC33jp/dNuxx4dOHlSVpsg3z7cAHwYeCRJDu7sU8DVyRZQ69N3F7gYwNVKGlRDfLtw3eYvWekvR6kJcxfNEpqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKkxyJ2XAEiyF3gROAwcqqq1SZYDtwNn0rv70oeq6heDvpek0RvWkcIfV9WaqlrbrW8CtlfVamB7ty5pCRjV6cM6YEu3vAW4bETvI2nIhhEKBXwzyUNJNnZjp3UdpKY7SZ06cyP7PkiTaeBrCsAFVbUvyanAtiQ/nM9GVbUZ2AzwxiyvIdQhaQgGPlKoqn3d40HgLnrNXw5M93/oHg8O+j6SFsegHaJO7DpOk+RE4H30mr9sBTZ00zYAdw/yPpIWz6CnD6cBd/WaRfE64D+q6r+SPAjckeRK4CfABwd8H0mLZKBQqKqngT+cZfw54KJBXlvSePiLRkkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1Fjw/RSSvI1eb4dpZwF/D5wE/A3w027801V1z4IrlLSoFhwKVfU4sAYgyTHAs/Tu0fhR4ItV9fmhVChpUQ3r9OEi4Kmq+vGQXk/SmAwrFNYDt/atX51kV5Kbkpw8pPeQtAgGDoUkxwEfAP6zG7oeOJveqcV+4Lo5trMZjDSBhnGkcAnwcFUdAKiqA1V1uKpeBW6g1wfiCFW1uarWVtXaY1k2hDIkDcMwQuEK+k4dppvAdC6n1wdC0hIx0C3ek5wAvBf4WN/w55Ksoddjcu+M5yRNuEH7PrwEvGnG2IcHqkjSWPmLRkkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1JhXKHQ3YD2Y5NG+seVJtiV5sns8uRtPki8l2dPdvPXcURUvafjme6TwFeDiGWObgO1VtRrY3q1D756Nq7u/jfRu5CppiZhXKFTVfcDPZwyvA7Z0y1uAy/rGb66e+4GTZty3UdIEG+SawmlVtR+gezy1G18BPNM3b6obk7QEDHSPxjlklrE6YlKykd7pBcdzwgjKkLQQgxwpHJg+LegeD3bjU8DKvnlnAPtmbmzfB2kyDRIKW4EN3fIG4O6+8Y9030KcDzw/fZohafLN6/Qhya3Ae4A3J5kC/gH4LHBHkiuBnwAf7KbfA1wK7AFeoteFWtISMa9QqKor5njqolnmFnDVIEVJGh9/0SipYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqTGUUNhjkYw/5zkh12zl7uSnNSNn5nkl0l2dn9fHmXxkoZvPkcKX+HIRjDbgN+vqj8AngCu6Xvuqapa0/19fDhlSlosRw2F2RrBVNU3q+pQt3o/vTs2S/otMIxrCn8NfKNvfVWS7yX5dpJ3z7VRko1JdiTZ8QovD6EMScMwUDOYJJ8BDgG3dEP7gbdU1XNJ3gl8Pcnbq+qFmdtW1WZgM8Abs/yIZjGSxmPBRwpJNgB/BvxldwdnqurlqnquW34IeAp46zAKlbQ4FhQKSS4G/g74QFW91Dd+SpJjuuWz6HWefnoYhUpaHEc9fZijEcw1wDJgWxKA+7tvGi4E/jHJIeAw8PGqmtmtWtIEO2oozNEI5sY55t4J3DloUZLGx180SmoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkxkL7Plyb5Nm+/g6X9j13TZI9SR5P8v5RFS5pNBba9wHgi339He4BSHIOsB54e7fNv03fnk3S0rCgvg+/wTrgtu4Grj8C9gDnDVCfpEU2yDWFq7u2cTclObkbWwE80zdnqhs7gn0fpMm00FC4HjgbWEOv18N13XhmmTtrT4eq2lxVa6tq7bEsW2AZkoZtQaFQVQeq6nBVvQrcwK9PEaaAlX1TzwD2DVaipMW00L4Pp/etXg5MfzOxFVifZFmSVfT6Pnx3sBIlLaaF9n14T5I19E4N9gIfA6iqx5LcAfyAXju5q6rq8GhKlzQK6Tq+jdUbs7zelYvGXYb0W+1b9dWHqmrt0eb5i0ZJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNRYaN+H2/t6PuxNsrMbPzPJL/ue+/Ioi5c0fEe98xK9vg//Atw8PVBVfzG9nOQ64Pm++U9V1ZphFShpcR01FKrqviRnzvZckgAfAv5kuGVJGpdBrym8GzhQVU/2ja1K8r0k307y7gFfX9Iim8/pw29yBXBr3/p+4C1V9VySdwJfT/L2qnph5oZJNgIbAY7nhAHLkDQsCz5SSPI64M+B26fHunZxz3XLDwFPAW+dbXubwUiTaZDThz8FflhVU9MDSU6Zbiib5Cx6fR+eHqxESYtpPl9J3gr8D/C2JFNJruyeWk976gBwIbAryfeBrwIfr6r5NqeVNAHm8+3DFXOM/9UsY3cCdw5elqRx8ReNkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpMZ+brKxMcm+S3UkeS/KJbnx5km1JnuweT+7Gk+RLSfYk2ZXk3FF/CEnDM58jhUPAp6rq94DzgauSnANsArZX1Wpge7cOcAm927Ctpndj1uuHXrWkkTlqKFTV/qp6uFt+EdgNrADWAVu6aVuAy7rldcDN1XM/cFKS04deuaSReE3XFLqmMO8AHgBOq6r90AsO4NRu2grgmb7NproxSUvAvEMhyevp3X/xk7P1ceifOstYzfJ6G5PsSLLjFV6ebxmSRmxeoZDkWHqBcEtVfa0bPjB9WtA9HuzGp4CVfZufAeyb+Zr2fZAm03y+fQhwI7C7qr7Q99RWYEO3vAG4u2/8I923EOcDz0+fZkiafPNpG3cB8GHgkemW88Cngc8Cd3R9IH4CfLB77h7gUmAP8BLw0aFWLGmk5tP34TvMfp0A4KJZ5hdw1YB1SRoTf9EoqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGqkd/e0MReR/BT4X+Bn465lAG9madcPS/8zLPX6YbSf4Xer6pSjTZqIUABIsqOq1o67joVa6vXD0v8MS71+mIzP4OmDpIahIKkxSaGwedwFDGip1w9L/zMs9fphAj7DxFxTkDQZJulIQdIEGHsoJLk4yeNJ9iTZNO565ivJ3iSPJNmZZEc3tjzJtiRPdo8nj7vOfkluSnIwyaN9Y7PW3PUC/VK3X3YlOXd8lf9/rbPVf22SZ7v9sDPJpX3PXdPV/3iS94+n6l9LsjLJvUl2J3ksySe68cnaB1U1tj/gGOAp4CzgOOD7wDnjrOk11L4XePOMsc8Bm7rlTcA/jbvOGfVdCJwLPHq0mun1A/0GvZaB5wMPTGj91wJ/O8vcc7p/T8uAVd2/s2PGXP/pwLnd8huAJ7o6J2ofjPtI4TxgT1U9XVW/Am4D1o25pkGsA7Z0y1uAy8ZYyxGq6j7g5zOG56p5HXBz9dwPnJTk9MWpdHZz1D+XdcBtVfVyVf2IXsPj80ZW3DxU1f6qerhbfhHYDaxgwvbBuENhBfBM3/pUN7YUFPDNJA8l2diNnVZV+6H3DwA4dWzVzd9cNS+lfXN1d3h9U98p20TXn+RM4B3AA0zYPhh3KMzWzXqpfB1yQVWdC1wCXJXkwnEXNGRLZd9cD5wNrAH2A9d14xNbf5LXA3cCn6yqF37T1FnGRv4Zxh0KU8DKvvUzgH1jquU1qap93eNB4C56h6YHpg/vuseD46tw3uaqeUnsm6o6UFWHq+pV4AZ+fYowkfUnOZZeINxSVV/rhidqH4w7FB4EVidZleQ4YD2wdcw1HVWSE5O8YXoZeB/wKL3aN3TTNgB3j6fC12SumrcCH+mugJ8PPD99iDtJZpxjX05vP0Cv/vVJliVZBawGvrvY9fVLEuBGYHdVfaHvqcnaB+O8Gtt3hfUJeleHPzPueuZZ81n0rmx/H3hsum7gTcB24Mnucfm4a51R9630DrFfofd/oSvnqpneoeu/dvvlEWDthNb/7119u+j9R3R63/zPdPU/DlwyAfX/Eb3D/13Azu7v0knbB/6iUVJj3KcPkiaMoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhr/BxF5SIxmMM0zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = 34\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(Y_val[img,:,:,0])\n",
    "# plt.subplot(122)\n",
    "plt.imshow(X_val_pred[img,:,:,0]>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_images(test_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([np.pad(rescale(x, 2),((11,11),(11,11),(0,0)), mode = 'constant') for x in X_test], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flip = np.array([np.fliplr(x) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack((X_test, X_test_flip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict(X_test, batch_size=32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip back and take mean\n",
    "Y_test_pred = (Y_test_pred[:18000]+np.array([np.fliplr(x) for x in Y_test_pred[18000]]))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = unpad(Y_test_pred)>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 1, 101, 101)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0231e49b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Y_test_pred[5,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_rle = [rle_encode(x) for x in Y_test_pred[:,0,:,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 94 102 94 203 93 304 92 405 90 506 89 607 87 708 86 807 1 809 85 905 4 910 84 1004 6 1011 82 1104 7 1112 80 1204 8 1213 78 1305 8 1314 76 1406 8 1415 74 1508 7 1516 72 1611 5 1617 70 1712 5 1718 68 1814 4 1819 66 1918 1 1920 64 2021 62 2122 60 2223 58 2324 55 2425 53 2526 52 2627 50 2728 46 2829 41 2930 38 3031 36 3132 33 3233 31 3334 29 3435 26 3536 24 3637 22 3738 18 3839 14 3940 8 4042 3'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_rle[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {file[:-4]:Y_test_rle[i] for i, file in enumerate(os.listdir(test_path+'images'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sub = pd.DataFrame.from_dict(pred_dict, orient = 'index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/submission_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
