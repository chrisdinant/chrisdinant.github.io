<!DOCTYPE html>
<html lang="en">

<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>


<head>
          <title>Transferred Learnings</title>
        <meta charset="utf-8" />


    <meta name="tags" content="naive-Bayes" />

        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="stylesheet" href="/theme/css/jupyter.css" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <!--[if lte IE 8]><script src="/theme/js/ie/html5shiv.js"></script><![endif]-->
        <!--[if lte IE 8]><link rel="stylesheet" href="/theme/css/ie8.css" /><![endif]-->
</head>

<body>
        <header id="banner" class="body">
                <h1><a href="./">Transferred Learnings <strong></strong></a></h1>
        </header><!-- /#banner -->
<!-- Sidebar -->
            <div id="sidebar">

                <!-- Logo -->
                    <h1 id="logo"><a href="/">Transferred Learnings</a></h1>
                    <!-- Text -->
                    <section class="box text-style1">
                        <div class="inner">
                            <p>
                                <strong>My long term memory is very short</strong><br />
                            </p>
                        </div>
                    </section>
                <!-- Nav -->
                    <nav id="nav">
                        <ul>                            
                            <li><a href="./pages/about-me.html">Whose blog is this?</a></li>
                            <li><a href="./category/data-science">Data Science</a></li>
                            <li><a href="./category/not-data-science">Not Data Science</a></li>
                        </ul>
                    </nav>

                <!-- Search -->
                    <!-- <section class="box search">
                        <form method="post" action="#">
                            <input type="text" class="text" name="search" placeholder="Search" />
                        </form>
                    </section> -->

                

                <!-- Recent Posts -->
                    <section class="box recent-posts">
                        <header>
                            <h2>Contact Me</h2>
                        </header>
                        <ul>
                            <li><a class="icon fa-envelope" href="mailto:chris.dinant@gmail.com"> Email</a></li>
                            <li><a class="icon fa-twitter" href="https://twitter.com/chrisdinant"> Twitter</a></li>
                            <li><a class="icon fa-linkedin" href="https://www.linkedin.com/in/chris-dinant/"> LinkedIn</a></li>
                            <li><a class="icon fa-github" href="https://github.com/chrisdinant"> Github</a></li>
                            
                        </ul>
                    </section>



                <!-- Copyright -->
                    <ul id="copyright">
                        <li>Powered by <a href="http://getpelican.com/">Pelican</a>.</li>
                        <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                        <li>Modified under a <a href="https://creativecommons.org/licenses/by/3.0/">CC:BY</a> license.</li>
                    </ul>

            </div><!-- /#menu -->
<div id="content">
<div class="inner">
        <article class="box post post-excerpt">
                <header> 
                <h2><a href="./naive-Bayes.html" rel="bookmark" title="Permalink to What's so naive about naive Bayes?">What's so naive about naive Bayes?</a></h2> 
                <p>Assuming feature independence tends to help classification accuracy</p>
                </header>
                <div class="info">
                    <span class="date" datetime="2018-10-28T00:00:00+02:00"><span class="month">Oct</span> <span class="day">28</span> <span class="month"> 2018</span></span>
                    <ul class="stats">
                                    <li><a href="mailto:?Subject=What's so naive about naive Bayes?&Body=I%20saw%20this%20and%20thought%20of%20you!%20 ./naive-Bayes.html" class="icon fa-envelope">&nbsp;</a></li>
                                    <li><a href="http://reddit.com/submit?url=./naive-Bayes.html&title=#What's so naive about naive Bayes?" class="icon fa-reddit">&nbsp;</a></li>
                                    <li><a href="https://twitter.com/share?url=./naive-Bayes.html&text=&hashtags=GnotC" class="icon fa-twitter">&nbsp;</a></li>
                                    <li><a href="https://www.facebook.com/sharer.php?u=./naive-Bayes.html" class="icon fa-facebook">&nbsp;</a></li>
                                </ul>
                </div><!-- /.post-info -->
                <div class="entry-content"> &nbsp; </div><!-- /.entry-content -->
        </article>
    <p><img alt="Naive Art" src="./images/naive-art_ivan_generalic.jpg" style="width: 1309px; height: auto; max-width: 100%;"/>
<em>Naive art by Ivan Generalic</em></p>
<p>Naive Bayes (NB) is 'naive' because it makes the assumption that features of a measurement are independent of each other. This is naive because it is (almost) never true. Here is why NB works anyway.  </p>
<p>NB is a very intuitive classification algorithm. It asks the question, "Given these features, does this measurement belong to class A or B?", and answers it by taking the proportion of all previous measurements with the same features belonging to class A multiplied by the proportion of all measurements in class A. If this number is bigger then the corresponding calculation for class B then we say the measurement belongs in class A. Simple, right?  </p>
<p>Of course in practice we will rarely see many measurements with identical feature sets. In fact if we had to rely on a measurement to be identical to some previously measured data points we would only be able to classify exact duplicates, making Bayes' rule practically useless for classification.  </p>
<p>Now if instead we make the naive assumption that all features are independent of each other, then we don't have to rely on exact duplicates in our training data set to make a classification. We can simply take each feature separately and determine proportion of previous measurements that belong to class A that have the same value for this feature only. Then we do the same with all other features and take the product. We again multiply this with the proportion of class A in the data set and see if this number is larger than if we do the corresponding calculation for class B. It's cheating, but it works.  </p>
<p>The great thing about NB is that the naive assumption actually tends to help the classification. Think of it this way: if two features are actually dependent, say, hair length and gender, then assuming they are independent means you get to double-count evidence. If both gender and long hair are more associated with being a Justin Bieber fan, then assuming independence made you even more sure that she's a Belieber. And perhaps a bit naive.</p>
<p><em>This was previously published by the Medium.com publication Towards Data Science, <a href="https://towardsdatascience.com/whats-so-naive-about-naive-bayes-58166a6a9eba">here</a></em></p>
<p>Δ9</p>

  </div><!-- /.entry-content -->
  <!-- Pagination -->
            <div class="pagination">
              <a class="button previous" href="./entropy-and-information-gain.html">
             Entropy and Information Gain
         </a>
              <a href="./custom-pixels.html" class="button next">Music Video</a>
            </div>
  <!-- disqus  -->         
</div>
</div>
        <!-- This jQuery line finds any span that contains code highlighting classes and then selects the parent <pre> tag and adds a border. 
        This is done as a workaround to visually distinguish the code inputs and outputs -->
        <script>
            $( ".hll, .n, .c, .err, .s1, .ss, .bp, .vc, .vg, .vi, .il, .kn, .nn" ).parent( "pre" ).css( "border", "1px solid #DEDEDE" );
        </script>
<!-- /#contentinfo -->

</body>
</html>